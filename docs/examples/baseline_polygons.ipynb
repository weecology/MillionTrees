{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TreePolygons - Baseline DeepForest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we illustrate the structure of the datasets and performance of the baseline polygon model against the official training split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib\n",
    "\n",
    "if os.path.basename(os.getcwd()) == 'examples':\n",
    "    sys.path.append(\"../\")\n",
    "\n",
    "import milliontrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the DeepForest bounding box model available at https://deepforest.readthedocs.io/en/latest/user_guide/02_prebuilt.html#tree-crown-detection-model. Since a box is a type of four pointed polygon, this can act as the minimum performance for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepforest import main\n",
    "\n",
    "m = main.deepforest()\n",
    "m.load_model(\"weecology/deepforest-tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepforest import get_data\n",
    "from deepforest.visualize import plot_results\n",
    "from deepforest.utilities import read_file\n",
    "\n",
    "boxes = m.predict_image(path=get_data(\"OSBS_029.png\"))\n",
    "\n",
    "print(boxes.head())\n",
    "plot_results(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the box dataset\n",
    "from milliontrees import get_dataset\n",
    "from milliontrees.common.data_loaders import get_eval_loader\n",
    "\n",
    "polygon_dataset = get_dataset(\n",
    "    \"TreePolygons\", root_dir=\"/orange/ewhite/DeepForest/MillionTrees/\")\n",
    "polygon_test_data = polygon_dataset.get_subset(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each iteration of the loader yields metadata, image, targets, let's look at their shapes and structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata, image, targets = polygon_test_data[250]\n",
    "\n",
    "print(f\"Metadata shape: {metadata.shape}\")\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Targets: {targets.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask viz not ready.\n",
    "#The general workflow is to yield a image, and targets (orange), make a predictions (blue) and evaluate the metric.\n",
    "#image_path = polygon_dataset._filename_id_to_code[int(metadata[0])]\n",
    "#image_path = os.path.join(polygon_dataset._data_dir._str, \"images\",image_path)\n",
    "\n",
    "# Load the image, in this case DeepForest expects a numpy array, channels first, 0-255.\n",
    "#channels_first = image.permute(1, 2, 0).numpy() * 255\n",
    "#boxes = m.predict_image(channels_first)\n",
    "#ground_truth = read_file(pd.DataFrame(targets[\"y\"].numpy(),columns=[\"xmin\",\"ymin\",\"xmax\",\"ymax\"]))\n",
    "#ground_truth[\"label\"] = \"Tree\"\n",
    "#plot_results(boxes, ground_truth, image=channels_first.astype(\"int32\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation example\n",
    "\n",
    "Every model will output predictions in a slightly different way. MillionTrees expects a dictionary of tensors, same format between predictions and ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = {}\n",
    "y_pred[\"y\"] = torch.tensor(boxes[[\"xmin\", \"ymin\", \"xmax\",\n",
    "                                  \"ymax\"]].values.astype(\"float32\"))\n",
    "y_pred[\"labels\"] = torch.tensor(\n",
    "    boxes.label.apply(lambda x: m.label_dict[x]).values.astype(np.int64))\n",
    "y_pred[\"scores\"] = torch.tensor(boxes.score.values.astype(\"float32\"))\n",
    "\n",
    "# The eval method takes in batches, so wrap this one example in a liste\n",
    "# To recover just one metric, you can grab the object directly.\n",
    "polygon_test_data.eval([y_pred], [targets],\n",
    "                       metadata=torch.unsqueeze(metadata, dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation dictionary is broken down by 'sources' which are individual projects contributed to the MillionTrees project, listed on the 'datasets' page on the docs. For each source the dictionary gives a count of the number of images, and then the bounding box mAP accuracy score. Then it gives the average within-group 'wg' score, and the average over all groups. In this example, we just have 1 image from 1 source, so the rest of groups are nan. Let's look at the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most evaluation workflows there will be some intermediary code to format the output of whatever prediction workflow to the desired eval format. It would also be nice to have a plotting function to see some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "def format_deepforest_prediction(images, metadata, targets, m, batch_index):\n",
    "    # Suppress user warnings to make more readable\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    images = torch.tensor(images)\n",
    "    predictions = m.predict_step(images, batch_index)\n",
    "    batch_results = []\n",
    "    for image_metadata, pred, image_targets, image in zip(\n",
    "            metadata, predictions, targets, images):\n",
    "        basename = polygon_dataset._filename_id_to_code[int(image_metadata[0])]\n",
    "        if pred is None:\n",
    "            y_pred = {}\n",
    "            y_pred[\"y\"] = torch.zeros(4)\n",
    "            y_pred[\"labels\"] = torch.zeros(1)\n",
    "            y_pred[\"scores\"] = torch.zeros(1)\n",
    "        else:\n",
    "            pred.root_dir = os.path.join(polygon_dataset._data_dir._str,\n",
    "                                         \"images\")\n",
    "            pred[\"image_path\"] = basename\n",
    "            # Reformat to milliontrees format\n",
    "            y_pred = {}\n",
    "            y_pred[\"y\"] = torch.tensor(pred[[\"xmin\", \"ymin\", \"xmax\",\n",
    "                                             \"ymax\"]].values.astype(\"float32\"))\n",
    "            y_pred[\"labels\"] = torch.tensor(pred.label)\n",
    "            y_pred[\"scores\"] = torch.tensor(pred.score.values.astype(\"float32\"))\n",
    "        batch_results.append(y_pred)\n",
    "\n",
    "    return batch_results, predictions\n",
    "\n",
    "\n",
    "# Helper function to plot evaluation results\n",
    "\n",
    "\n",
    "def plot_eval_results(y_pred, pred, image_targets, image, batch_index):\n",
    "    basename = pred.image_path.unique()[0]\n",
    "    ground_truth = read_file(\n",
    "        pd.DataFrame(image_targets[\"y\"].numpy(),\n",
    "                     columns=[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]))\n",
    "    ground_truth[\"label\"] = \"Tree\"\n",
    "    predictions_df = read_file(pred)\n",
    "    predictions_df[\"label\"] = \"Tree\"\n",
    "    # Make image channel last\n",
    "    image = image.permute(1, 2, 0).numpy() * 255\n",
    "    accuracy = polygon_dataset.metrics[\"recall\"]._recall(image_targets[\"y\"],\n",
    "                                                         y_pred[\"y\"],\n",
    "                                                         iou_threshold=0.3)\n",
    "    plot_results(predictions_df, ground_truth, image=image.astype(\"int32\"))\n",
    "    print(\n",
    "        f\"Image: {basename}, index {batch_index} with Detection Recall: {accuracy.item():.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the test loader\n",
    "test_loader = get_eval_loader(\"standard\", polygon_test_data, batch_size=32)\n",
    "\n",
    "# Print the length of the test loader\n",
    "print(\"There are {} batches in the test loader\".format(len(test_loader)))\n",
    "\n",
    "# Get predictions for the full test set\n",
    "all_y_pred = []\n",
    "all_y_true = []\n",
    "\n",
    "batch_index = 0\n",
    "for batch in test_loader:\n",
    "    metadata, images, targets = batch\n",
    "    # Get the original DeepForest, and MillionTrees formatted predictions, this is just for plotting, otherwise you just need y_pred.\n",
    "    milliontrees_format, deepforest_format = format_deepforest_prediction(\n",
    "        images, metadata, targets, m, batch_index)\n",
    "    for image_metadata, y_pred, pred, image_targets, image in zip(\n",
    "            metadata, milliontrees_format, deepforest_format, targets, images):\n",
    "        # Plot every 250th image\n",
    "        if batch_index % 250 == 0:\n",
    "            plot_eval_results(y_pred, pred, image_targets, image, batch_index)\n",
    "        # Gather all predictions and ground truth\n",
    "        all_y_pred.append(y_pred)\n",
    "        all_y_true.append(image_targets)\n",
    "        batch_index += 1\n",
    "\n",
    "# Evaluate\n",
    "polygon_dataset.eval(all_y_pred, all_y_true, polygon_test_data.metadata_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MillionTrees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
