#!/usr/bin/env python3
"""
Test script for MillionTrees visualization functionality.
Tests the core functions with sample data.
"""

import pandas as pd
import os
import tempfile
import numpy as np
from visualize_datasets_concise import load_all_data, visualize_annotations, create_splits

def create_sample_data():
    """Create sample test data."""
    sample_data = pd.DataFrame({
        'source': ['Test Source 1', 'Test Source 2'] * 10,
        'filename': [f'test_image_{i}.png' for i in range(20)],
        'dataset_type': ['TreeBoxes'] * 10 + ['TreePoints'] * 10,
        'csv_path': ['/tmp/test_path.csv'] * 20,
        'xmin': np.random.rand(20) * 100,
        'ymin': np.random.rand(20) * 100,
        'xmax': np.random.rand(20) * 100 + 100,
        'ymax': np.random.rand(20) * 100 + 100,
        'label': ['Tree'] * 20
    })
    return sample_data

def test_data_loading():
    """Test data loading functionality."""
    print("Testing data loading...")
    try:
        # This will likely fail due to missing paths, but tests the function structure
        data = load_all_data()
        print(f"âœ“ Data loading function works (loaded {len(data)} rows)")
        return True
    except Exception as e:
        print(f"âš  Data loading test failed (expected - no test data): {e}")
        return False

def test_mini_dataset_creation():
    """Test mini dataset creation with sample data."""
    print("Testing mini dataset creation...")
    try:
        sample_data = create_sample_data()
        
        # Simulate mini dataset creation
        mini_data = pd.concat([
            source_data[source_data['filename'].isin(
                source_data.groupby('filename').size().nlargest(5).index
            )] for _, source_data in sample_data.groupby('source')
        ])
        
        print(f"âœ“ Mini dataset creation works ({len(mini_data)} rows from {mini_data['source'].nunique()} sources)")
        return True
    except Exception as e:
        print(f"âœ— Mini dataset creation failed: {e}")
        return False

def test_split_creation():
    """Test reviewer split functionality."""
    print("Testing split creation...")
    try:
        sample_data = create_sample_data()
        
        # Test split logic
        images = sample_data['filename'].unique()
        np.random.shuffle(images)
        splits = np.array_split(images, 4)
        
        # Verify splits
        total_images = sum(len(split) for split in splits)
        assert total_images == len(images), "Split sizes don't match original"
        
        print(f"âœ“ Split creation works (4 splits: {[len(s) for s in splits]})")
        return True
    except Exception as e:
        print(f"âœ— Split creation failed: {e}")
        return False

def test_file_naming():
    """Test safe filename generation."""
    print("Testing filename generation...")
    try:
        test_cases = [
            ("Test Source", "image.png", "Test_Source_image.png"),
            ("Source/With/Slashes", "test.jpg", "Source_With_Slashes_test.png"),
            ("Source.With.Dots", "file.tif", "Source_With_Dots_file.png")
        ]
        
        for source, filename, expected in test_cases:
            safe_name = f"{source.replace(' ', '_').replace('/', '_').replace('.', '_')}_{os.path.splitext(os.path.basename(filename))[0]}.png"
            assert safe_name == expected, f"Expected {expected}, got {safe_name}"
        
        print("âœ“ Filename generation works correctly")
        return True
    except Exception as e:
        print(f"âœ— Filename generation failed: {e}")
        return False

def main():
    """Run all tests."""
    print("=" * 50)
    print("MillionTrees Visualization Test Suite")
    print("=" * 50)
    
    tests = [
        test_data_loading,
        test_mini_dataset_creation, 
        test_split_creation,
        test_file_naming
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        if test():
            passed += 1
        print()
    
    print("=" * 50)
    print(f"Test Results: {passed}/{total} tests passed")
    
    if passed == total:
        print("ðŸŽ‰ All tests passed! The visualization scripts should work correctly.")
    else:
        print("âš  Some tests failed. Check the implementation.")
    
    print("=" * 50)

if __name__ == "__main__":
    main()